{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "LAB_TEXT_MachineTranslation_DE_EN.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "vHAOzpf9qSwG",
        "B_R6rzXhqSwY"
      ]
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLMIZiAPqSvx",
        "colab_type": "text"
      },
      "source": [
        "### Import Required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRkAXLnZqSvy",
        "colab_type": "code",
        "outputId": "875ae188-f569-4ab9-c993-72d992c5ac41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import string\n",
        "import re\n",
        "from numpy import array, argmax, random, take\n",
        "import pandas as pd\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, Embedding, Bidirectional, RepeatVector, TimeDistributed\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import load_model\n",
        "from keras import optimizers\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "pd.set_option('display.max_colwidth', 200)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-3J_UnpqYOQ",
        "colab_type": "code",
        "outputId": "9dd7d6b5-c705-438d-8f4e-cc03b8d955d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EohJnqtIq_fh",
        "colab_type": "code",
        "outputId": "7e61ad9b-a474-4e14-900e-190899175a75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd drive/'My Drive'/TEXT/Machine_learning_ES"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/TEXT/Machine_learning_ES\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1Sq3hudqSv4",
        "colab_type": "text"
      },
      "source": [
        "### Read Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMZJWfVJqSv5",
        "colab_type": "text"
      },
      "source": [
        "Our data is a text file of English-Spanish sentence pairs. First we will read the file using the function defined below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NDfg7zIUqSv5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# function to read raw text file\n",
        "def read_text(filename):\n",
        "    # open the file\n",
        "    file = open(filename, mode='rt', encoding='utf-8')\n",
        "    # read all text\n",
        "    text = file.read()\n",
        "    file.close()\n",
        "    return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dl1Lo1dcqSv8",
        "colab_type": "text"
      },
      "source": [
        "Now let's define a function to split the text into English-Spanish pairs separated by '\\n' and then split these pairs into English sentences and Spanish sentences."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jcmg7Ne3qSv8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# split a text into sentences\n",
        "def to_lines(text):\n",
        "    sents = text.strip().split('\\n')\n",
        "    sents = [i.split('\\t') for i in sents]\n",
        "    return sents"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6sC1TQTeu-C",
        "colab_type": "code",
        "outputId": "9ef4fc17-4e4f-4117-b189-d5c2f7622a84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "de_eng\t     LAB_TEXT_MachineTranslation_DE_EN.ipynb  README.md  spa-eng.zip\n",
            "deu-eng.zip  model.h1.24_jan_19\t\t\t      spa-eng\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCCz1PL-qSwA",
        "colab_type": "text"
      },
      "source": [
        "__Download the data from [here.](http://www.manythings.org/anki/deu-eng.zip)__ and extract \"deu.txt\" in your working directory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NaMYlUN1qSwA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = read_text(\"spa-eng/spa.txt\")\n",
        "spa_eng = to_lines(data)\n",
        "spa_eng = array(spa_eng)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-izsqHwLqSwD",
        "colab_type": "text"
      },
      "source": [
        "The actual data contains over 150,000 sentence-pairs. However, we will use the first 50,000 sentence pairs only to reduce the training time of the model. You can change this number as per you system computation power."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MwTqODsVqSwD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "spa_eng = spa_eng[:50,:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYJNLQa8qSwG",
        "colab_type": "text"
      },
      "source": [
        "### Text Pre-Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHAOzpf9qSwG",
        "colab_type": "text"
      },
      "source": [
        "#### Text Cleaning\n",
        "\n",
        "Let's take a look at our data, then we will decide which pre-processing steps to adopt."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "klkGBZ08qSwH",
        "colab_type": "code",
        "outputId": "1e491ea3-411e-43aa-aad8-c13cb450cd96",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "spa_eng"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['Go.', 'Ve.',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #4986655 (cueyayotl)'],\n",
              "       ['Go.', 'Vete.',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #4986656 (cueyayotl)'],\n",
              "       ['Go.', 'Vaya.',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #4986657 (cueyayotl)'],\n",
              "       ['Go.', 'Váyase.',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #6586271 (arh)'],\n",
              "       ['Hi.', 'Hola.',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #431975 (Leono)'],\n",
              "       ['Run!', '¡Corre!',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #906328 (papabear) & #1685404 (Elenitigormiti)'],\n",
              "       ['Run!', '¡Corran!',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #906328 (papabear) & #5213896 (cueyayotl)'],\n",
              "       ['Run!', '¡Corra!',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #906328 (papabear) & #8005613 (Seael)'],\n",
              "       ['Run!', '¡Corred!',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #906328 (papabear) & #8005615 (Seael)'],\n",
              "       ['Run.', 'Corred.',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #4008918 (JSakuragi) & #6681472 (arh)'],\n",
              "       ['Who?', '¿Quién?',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #2083030 (CK) & #2122720 (Shishir)'],\n",
              "       ['Wow!', '¡Órale!',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #52027 (Zifre) & #4726230 (cueyayotl)'],\n",
              "       ['Fire!', '¡Fuego!',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #1829639 (Spamster) & #1832096 (Shishir)'],\n",
              "       ['Fire!', '¡Incendio!',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #1829639 (Spamster) & #3112459 (marcelostockle)'],\n",
              "       ['Fire!', '¡Disparad!',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #1829639 (Spamster) & #3112460 (marcelostockle)'],\n",
              "       ['Help!', '¡Ayuda!',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #435084 (lukaszpp) & #927374 (mrc3306)'],\n",
              "       ['Help!', '¡Socorro! ¡Auxilio!',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #435084 (lukaszpp) & #1216469 (wallebot)'],\n",
              "       ['Help!', '¡Auxilio!',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #435084 (lukaszpp) & #1343034 (marcelostockle)'],\n",
              "       ['Jump!', '¡Salta!',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #1102981 (jamessilver) & #1503535 (marcelostockle)'],\n",
              "       ['Jump.', 'Salte.',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #631038 (Shishir) & #607995 (arashi_29)'],\n",
              "       ['Stop!', '¡Parad!',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #448320 (FeuDRenais) & #4347076 (saverius)'],\n",
              "       ['Stop!', '¡Para!',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #448320 (FeuDRenais) & #5669421 (cueyayotl)'],\n",
              "       ['Stop!', '¡Pare!',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #448320 (FeuDRenais) & #5669422 (cueyayotl)'],\n",
              "       ['Wait!', '¡Espera!',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #1744314 (belgavox) & #2122717 (Shishir)'],\n",
              "       ['Wait.', 'Esperen.',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #3048304 (camilozeta) & #3048255 (hayastan)'],\n",
              "       ['Go on.', 'Continúa.',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #2230774 (CK) & #4940109 (Francisco_M)'],\n",
              "       ['Go on.', 'Continúe.',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #2230774 (CK) & #4940116 (Francisco_M)'],\n",
              "       ['Hello!', 'Hola.',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #373330 (CK) & #431975 (Leono)'],\n",
              "       ['I ran.', 'Corrí.',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #5828607 (CK) & #6682393 (arh)'],\n",
              "       ['I ran.', 'Corría.',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #5828607 (CK) & #6682394 (arh)'],\n",
              "       ['I try.', 'Lo intento.',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #20776 (CK) & #1449864 (nullsoul9)'],\n",
              "       ['I won!', '¡He ganado!',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #2005192 (CK) & #2351590 (Shishir)'],\n",
              "       ['Oh no!', '¡Oh, no!',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #1299275 (CK) & #5056288 (don_ramon)'],\n",
              "       ['Relax.', 'Tomátelo con soda.',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #1722133 (shanghainese) & #5124533 (ecorralest101)'],\n",
              "       ['Shoot!', '¡Fuego!',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #7422159 (CM) & #1832096 (Shishir)'],\n",
              "       ['Shoot!', '¡Disparad!',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #7422159 (CM) & #3112460 (marcelostockle)'],\n",
              "       ['Shoot!', '¡Disparen!',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #7422159 (CM) & #3285306 (cueyayotl)'],\n",
              "       ['Shoot!', '¡Dispara!',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #7422159 (CM) & #7936886 (Seael)'],\n",
              "       ['Shoot!', '¡Dispará!',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #7422159 (CM) & #7936887 (Seael)'],\n",
              "       ['Shoot!', '¡Dispare!',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #7422159 (CM) & #7936888 (Seael)'],\n",
              "       ['Smile.', 'Sonríe.',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #2764108 (CK) & #1852302 (Shishir)'],\n",
              "       ['Attack!', '¡Al ataque!',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #1972610 (CK) & #4554129 (swyter)'],\n",
              "       ['Attack!', '¡Atacad!',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #1972610 (CK) & #4554130 (swyter)'],\n",
              "       ['Attack!', '¡Ataque!',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #1972610 (CK) & #8005608 (Seael)'],\n",
              "       ['Attack!', '¡Ataquen!',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #1972610 (CK) & #8005609 (Seael)'],\n",
              "       ['Attack!', '¡Ataca!',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #1972610 (CK) & #8005610 (Seael)'],\n",
              "       ['Get up.', 'Levanta.',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #896158 (pauldhunt) & #5769212 (arh)'],\n",
              "       ['Go now.', 'Ve ahora mismo.',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #2230771 (CK) & #5165878 (cueyayotl)'],\n",
              "       ['Go now.', 'Id ahora mismo.',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #2230771 (CK) & #8005616 (Seael)'],\n",
              "       ['Go now.', 'Vaya ahora mismo.',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #2230771 (CK) & #8005617 (Seael)']],\n",
              "      dtype='<U332')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQkOdGvQqSwM",
        "colab_type": "text"
      },
      "source": [
        "We will get rid of the punctuation marks, and then convert the text to lower case."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pci3hGBPqSwM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Remove punctuation\n",
        "spa_eng[:,0] = [s.translate(str.maketrans('', '', string.punctuation)) for s in spa_eng[:,0]]\n",
        "spa_eng[:,1] = [s.translate(str.maketrans('', '', string.punctuation)) for s in spa_eng[:,1]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXLCPbTbqSwP",
        "colab_type": "code",
        "outputId": "a4750e0d-1cc4-4176-ba0a-c4815e83f54b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "spa_eng"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['Go', 'Ve',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #4986655 (cueyayotl)'],\n",
              "       ['Go', 'Vete',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #4986656 (cueyayotl)'],\n",
              "       ['Go', 'Vaya',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #4986657 (cueyayotl)'],\n",
              "       ['Go', 'Váyase',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #6586271 (arh)'],\n",
              "       ['Hi', 'Hola',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #431975 (Leono)'],\n",
              "       ['Run', '¡Corre',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #906328 (papabear) & #1685404 (Elenitigormiti)'],\n",
              "       ['Run', '¡Corran',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #906328 (papabear) & #5213896 (cueyayotl)'],\n",
              "       ['Run', '¡Corra',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #906328 (papabear) & #8005613 (Seael)'],\n",
              "       ['Run', '¡Corred',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #906328 (papabear) & #8005615 (Seael)'],\n",
              "       ['Run', 'Corred',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #4008918 (JSakuragi) & #6681472 (arh)'],\n",
              "       ['Who', '¿Quién',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #2083030 (CK) & #2122720 (Shishir)'],\n",
              "       ['Wow', '¡Órale',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #52027 (Zifre) & #4726230 (cueyayotl)'],\n",
              "       ['Fire', '¡Fuego',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #1829639 (Spamster) & #1832096 (Shishir)'],\n",
              "       ['Fire', '¡Incendio',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #1829639 (Spamster) & #3112459 (marcelostockle)'],\n",
              "       ['Fire', '¡Disparad',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #1829639 (Spamster) & #3112460 (marcelostockle)'],\n",
              "       ['Help', '¡Ayuda',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #435084 (lukaszpp) & #927374 (mrc3306)'],\n",
              "       ['Help', '¡Socorro ¡Auxilio',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #435084 (lukaszpp) & #1216469 (wallebot)'],\n",
              "       ['Help', '¡Auxilio',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #435084 (lukaszpp) & #1343034 (marcelostockle)'],\n",
              "       ['Jump', '¡Salta',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #1102981 (jamessilver) & #1503535 (marcelostockle)'],\n",
              "       ['Jump', 'Salte',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #631038 (Shishir) & #607995 (arashi_29)'],\n",
              "       ['Stop', '¡Parad',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #448320 (FeuDRenais) & #4347076 (saverius)'],\n",
              "       ['Stop', '¡Para',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #448320 (FeuDRenais) & #5669421 (cueyayotl)'],\n",
              "       ['Stop', '¡Pare',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #448320 (FeuDRenais) & #5669422 (cueyayotl)'],\n",
              "       ['Wait', '¡Espera',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #1744314 (belgavox) & #2122717 (Shishir)'],\n",
              "       ['Wait', 'Esperen',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #3048304 (camilozeta) & #3048255 (hayastan)'],\n",
              "       ['Go on', 'Continúa',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #2230774 (CK) & #4940109 (Francisco_M)'],\n",
              "       ['Go on', 'Continúe',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #2230774 (CK) & #4940116 (Francisco_M)'],\n",
              "       ['Hello', 'Hola',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #373330 (CK) & #431975 (Leono)'],\n",
              "       ['I ran', 'Corrí',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #5828607 (CK) & #6682393 (arh)'],\n",
              "       ['I ran', 'Corría',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #5828607 (CK) & #6682394 (arh)'],\n",
              "       ['I try', 'Lo intento',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #20776 (CK) & #1449864 (nullsoul9)'],\n",
              "       ['I won', '¡He ganado',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #2005192 (CK) & #2351590 (Shishir)'],\n",
              "       ['Oh no', '¡Oh no',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #1299275 (CK) & #5056288 (don_ramon)'],\n",
              "       ['Relax', 'Tomátelo con soda',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #1722133 (shanghainese) & #5124533 (ecorralest101)'],\n",
              "       ['Shoot', '¡Fuego',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #7422159 (CM) & #1832096 (Shishir)'],\n",
              "       ['Shoot', '¡Disparad',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #7422159 (CM) & #3112460 (marcelostockle)'],\n",
              "       ['Shoot', '¡Disparen',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #7422159 (CM) & #3285306 (cueyayotl)'],\n",
              "       ['Shoot', '¡Dispara',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #7422159 (CM) & #7936886 (Seael)'],\n",
              "       ['Shoot', '¡Dispará',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #7422159 (CM) & #7936887 (Seael)'],\n",
              "       ['Shoot', '¡Dispare',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #7422159 (CM) & #7936888 (Seael)'],\n",
              "       ['Smile', 'Sonríe',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #2764108 (CK) & #1852302 (Shishir)'],\n",
              "       ['Attack', '¡Al ataque',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #1972610 (CK) & #4554129 (swyter)'],\n",
              "       ['Attack', '¡Atacad',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #1972610 (CK) & #4554130 (swyter)'],\n",
              "       ['Attack', '¡Ataque',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #1972610 (CK) & #8005608 (Seael)'],\n",
              "       ['Attack', '¡Ataquen',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #1972610 (CK) & #8005609 (Seael)'],\n",
              "       ['Attack', '¡Ataca',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #1972610 (CK) & #8005610 (Seael)'],\n",
              "       ['Get up', 'Levanta',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #896158 (pauldhunt) & #5769212 (arh)'],\n",
              "       ['Go now', 'Ve ahora mismo',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #2230771 (CK) & #5165878 (cueyayotl)'],\n",
              "       ['Go now', 'Id ahora mismo',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #2230771 (CK) & #8005616 (Seael)'],\n",
              "       ['Go now', 'Vaya ahora mismo',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #2230771 (CK) & #8005617 (Seael)']],\n",
              "      dtype='<U332')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "VvAl9X-LqSwS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# convert to lowercase\n",
        "for i in range(len(spa_eng)):\n",
        "    spa_eng[i,0] = spa_eng[i,0].lower()\n",
        "    \n",
        "    spa_eng[i,1] = spa_eng[i,1].lower()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drlNGf2aqSwV",
        "colab_type": "code",
        "outputId": "5137f342-dea2-47ec-880f-b739cc58829f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "spa_eng"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['go', 've',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #4986655 (cueyayotl)'],\n",
              "       ['go', 'vete',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #4986656 (cueyayotl)'],\n",
              "       ['go', 'vaya',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #4986657 (cueyayotl)'],\n",
              "       ['go', 'váyase',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #6586271 (arh)'],\n",
              "       ['hi', 'hola',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #431975 (Leono)'],\n",
              "       ['run', '¡corre',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #906328 (papabear) & #1685404 (Elenitigormiti)'],\n",
              "       ['run', '¡corran',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #906328 (papabear) & #5213896 (cueyayotl)'],\n",
              "       ['run', '¡corra',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #906328 (papabear) & #8005613 (Seael)'],\n",
              "       ['run', '¡corred',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #906328 (papabear) & #8005615 (Seael)'],\n",
              "       ['run', 'corred',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #4008918 (JSakuragi) & #6681472 (arh)'],\n",
              "       ['who', '¿quién',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #2083030 (CK) & #2122720 (Shishir)'],\n",
              "       ['wow', '¡órale',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #52027 (Zifre) & #4726230 (cueyayotl)'],\n",
              "       ['fire', '¡fuego',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #1829639 (Spamster) & #1832096 (Shishir)'],\n",
              "       ['fire', '¡incendio',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #1829639 (Spamster) & #3112459 (marcelostockle)'],\n",
              "       ['fire', '¡disparad',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #1829639 (Spamster) & #3112460 (marcelostockle)'],\n",
              "       ['help', '¡ayuda',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #435084 (lukaszpp) & #927374 (mrc3306)'],\n",
              "       ['help', '¡socorro ¡auxilio',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #435084 (lukaszpp) & #1216469 (wallebot)'],\n",
              "       ['help', '¡auxilio',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #435084 (lukaszpp) & #1343034 (marcelostockle)'],\n",
              "       ['jump', '¡salta',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #1102981 (jamessilver) & #1503535 (marcelostockle)'],\n",
              "       ['jump', 'salte',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #631038 (Shishir) & #607995 (arashi_29)'],\n",
              "       ['stop', '¡parad',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #448320 (FeuDRenais) & #4347076 (saverius)'],\n",
              "       ['stop', '¡para',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #448320 (FeuDRenais) & #5669421 (cueyayotl)'],\n",
              "       ['stop', '¡pare',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #448320 (FeuDRenais) & #5669422 (cueyayotl)'],\n",
              "       ['wait', '¡espera',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #1744314 (belgavox) & #2122717 (Shishir)'],\n",
              "       ['wait', 'esperen',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #3048304 (camilozeta) & #3048255 (hayastan)'],\n",
              "       ['go on', 'continúa',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #2230774 (CK) & #4940109 (Francisco_M)'],\n",
              "       ['go on', 'continúe',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #2230774 (CK) & #4940116 (Francisco_M)'],\n",
              "       ['hello', 'hola',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #373330 (CK) & #431975 (Leono)'],\n",
              "       ['i ran', 'corrí',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #5828607 (CK) & #6682393 (arh)'],\n",
              "       ['i ran', 'corría',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #5828607 (CK) & #6682394 (arh)'],\n",
              "       ['i try', 'lo intento',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #20776 (CK) & #1449864 (nullsoul9)'],\n",
              "       ['i won', '¡he ganado',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #2005192 (CK) & #2351590 (Shishir)'],\n",
              "       ['oh no', '¡oh no',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #1299275 (CK) & #5056288 (don_ramon)'],\n",
              "       ['relax', 'tomátelo con soda',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #1722133 (shanghainese) & #5124533 (ecorralest101)'],\n",
              "       ['shoot', '¡fuego',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #7422159 (CM) & #1832096 (Shishir)'],\n",
              "       ['shoot', '¡disparad',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #7422159 (CM) & #3112460 (marcelostockle)'],\n",
              "       ['shoot', '¡disparen',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #7422159 (CM) & #3285306 (cueyayotl)'],\n",
              "       ['shoot', '¡dispara',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #7422159 (CM) & #7936886 (Seael)'],\n",
              "       ['shoot', '¡dispará',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #7422159 (CM) & #7936887 (Seael)'],\n",
              "       ['shoot', '¡dispare',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #7422159 (CM) & #7936888 (Seael)'],\n",
              "       ['smile', 'sonríe',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #2764108 (CK) & #1852302 (Shishir)'],\n",
              "       ['attack', '¡al ataque',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #1972610 (CK) & #4554129 (swyter)'],\n",
              "       ['attack', '¡atacad',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #1972610 (CK) & #4554130 (swyter)'],\n",
              "       ['attack', '¡ataque',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #1972610 (CK) & #8005608 (Seael)'],\n",
              "       ['attack', '¡ataquen',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #1972610 (CK) & #8005609 (Seael)'],\n",
              "       ['attack', '¡ataca',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #1972610 (CK) & #8005610 (Seael)'],\n",
              "       ['get up', 'levanta',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #896158 (pauldhunt) & #5769212 (arh)'],\n",
              "       ['go now', 've ahora mismo',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #2230771 (CK) & #5165878 (cueyayotl)'],\n",
              "       ['go now', 'id ahora mismo',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #2230771 (CK) & #8005616 (Seael)'],\n",
              "       ['go now', 'vaya ahora mismo',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #2230771 (CK) & #8005617 (Seael)']],\n",
              "      dtype='<U332')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_R6rzXhqSwY",
        "colab_type": "text"
      },
      "source": [
        "#### Text to Sequence Conversion\n",
        "\n",
        "To feed our data in a Seq2Seq model, we will have to convert both the input and the output sentences into integer sequences of fixed length. Before that, let's visualise the length of the sentences. We will capture the lengths of all the sentences in two separate lists for English and Spanish, respectively."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5jFmqnYqSwY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# empty lists\n",
        "eng_l = []\n",
        "spa_l = []\n",
        "\n",
        "# populate the lists with sentence lengths\n",
        "for i in spa_eng[:,0]:\n",
        "    eng_l.append(len(i.split()))\n",
        "\n",
        "for i in spa_eng[:,1]:\n",
        "    spa_l.append(len(i.split()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNYZ58o1fJVE",
        "colab_type": "code",
        "outputId": "eda6182e-2f87-4541-f17e-e49850bc4ebd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        " spa_eng[:,1]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['ve', 'vete', 'vaya', 'váyase', 'hola', '¡corre', '¡corran',\n",
              "       '¡corra', '¡corred', 'corred', '¿quién', '¡órale', '¡fuego',\n",
              "       '¡incendio', '¡disparad', '¡ayuda', '¡socorro ¡auxilio',\n",
              "       '¡auxilio', '¡salta', 'salte', '¡parad', '¡para', '¡pare',\n",
              "       '¡espera', 'esperen', 'continúa', 'continúe', 'hola', 'corrí',\n",
              "       'corría', 'lo intento', '¡he ganado', '¡oh no',\n",
              "       'tomátelo con soda', '¡fuego', '¡disparad', '¡disparen',\n",
              "       '¡dispara', '¡dispará', '¡dispare', 'sonríe', '¡al ataque',\n",
              "       '¡atacad', '¡ataque', '¡ataquen', '¡ataca', 'levanta',\n",
              "       've ahora mismo', 'id ahora mismo', 'vaya ahora mismo'],\n",
              "      dtype='<U332')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSmbtoFoqSwa",
        "colab_type": "code",
        "outputId": "ebdff011-f079-4aa9-8b52-497d6a583b3d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "length_df = pd.DataFrame({'eng':eng_l, 'spa':spa_l})\n",
        "print(length_df)\n",
        "print(max(length_df.eng))\n",
        "print(max(length_df.spa))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    eng  spa\n",
            "0     1    1\n",
            "1     1    1\n",
            "2     1    1\n",
            "3     1    1\n",
            "4     1    1\n",
            "5     1    1\n",
            "6     1    1\n",
            "7     1    1\n",
            "8     1    1\n",
            "9     1    1\n",
            "10    1    1\n",
            "11    1    1\n",
            "12    1    1\n",
            "13    1    1\n",
            "14    1    1\n",
            "15    1    1\n",
            "16    1    2\n",
            "17    1    1\n",
            "18    1    1\n",
            "19    1    1\n",
            "20    1    1\n",
            "21    1    1\n",
            "22    1    1\n",
            "23    1    1\n",
            "24    1    1\n",
            "25    2    1\n",
            "26    2    1\n",
            "27    1    1\n",
            "28    2    1\n",
            "29    2    1\n",
            "30    2    2\n",
            "31    2    2\n",
            "32    2    2\n",
            "33    1    3\n",
            "34    1    1\n",
            "35    1    1\n",
            "36    1    1\n",
            "37    1    1\n",
            "38    1    1\n",
            "39    1    1\n",
            "40    1    1\n",
            "41    1    2\n",
            "42    1    1\n",
            "43    1    1\n",
            "44    1    1\n",
            "45    1    1\n",
            "46    2    1\n",
            "47    2    3\n",
            "48    2    3\n",
            "49    2    3\n",
            "2\n",
            "3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQVZLeGAqSwd",
        "colab_type": "code",
        "outputId": "17dd0da7-df6a-4123-b9cd-8fee268b687f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "length_df.hist(bins = 30)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_lJdSVDqSwf",
        "colab_type": "text"
      },
      "source": [
        "The maximum length of the German sentences is 11 and that of the English phrases is 8."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJt0Vq8WqSwg",
        "colab_type": "text"
      },
      "source": [
        "Let's vectorize our text data by using Keras's Tokenizer() class. It will turn our sentences into sequences of integers. Then we will pad those sequences with zeros to make all the sequences of same length."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBJgwrr9qSwh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# function to build a tokenizer\n",
        "def tokenization(lines):\n",
        "    tokenizer = Tokenizer()\n",
        "    tokenizer.fit_on_texts(lines)\n",
        "    return tokenizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVg3HQBVqSwk",
        "colab_type": "code",
        "outputId": "e1a1eb6d-5c2e-41a7-9039-c2d11551c4ea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# prepare english tokenizer\n",
        "eng_tokenizer = tokenization(spa_eng[:, 0])\n",
        "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
        "\n",
        "eng_length = 8\n",
        "print('English Vocabulary Size: %d' % eng_vocab_size)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "English Vocabulary Size: 26\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "esFaCWsnqSwn",
        "colab_type": "code",
        "outputId": "d5777988-bf7b-4d38-96a7-8dd3ad6cbf68",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# prepare Spanish tokenizer\n",
        "spa_tokenizer = tokenization(spa_eng[:, 1])\n",
        "spa_vocab_size = len(spa_tokenizer.word_index) + 1\n",
        "\n",
        "spa_length = 8\n",
        "print('Spanish Vocabulary Size: %d' % spa_vocab_size)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Spanish Vocabulary Size: 54\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QoQKcAq5qSwq",
        "colab_type": "code",
        "outputId": "68a1ba87-6f32-4e4d-a3c7-d178ae4468bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(spa_tokenizer.word_counts)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "OrderedDict([('ve', 2), ('vete', 1), ('vaya', 2), ('váyase', 1), ('hola', 2), ('¡corre', 1), ('¡corran', 1), ('¡corra', 1), ('¡corred', 1), ('corred', 1), ('¿quién', 1), ('¡órale', 1), ('¡fuego', 2), ('¡incendio', 1), ('¡disparad', 2), ('¡ayuda', 1), ('¡socorro', 1), ('¡auxilio', 2), ('¡salta', 1), ('salte', 1), ('¡parad', 1), ('¡para', 1), ('¡pare', 1), ('¡espera', 1), ('esperen', 1), ('continúa', 1), ('continúe', 1), ('corrí', 1), ('corría', 1), ('lo', 1), ('intento', 1), ('¡he', 1), ('ganado', 1), ('¡oh', 1), ('no', 1), ('tomátelo', 1), ('con', 1), ('soda', 1), ('¡disparen', 1), ('¡dispara', 1), ('¡dispará', 1), ('¡dispare', 1), ('sonríe', 1), ('¡al', 1), ('ataque', 1), ('¡atacad', 1), ('¡ataque', 1), ('¡ataquen', 1), ('¡ataca', 1), ('levanta', 1), ('ahora', 3), ('mismo', 3), ('id', 1)])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzegeUu-qSws",
        "colab_type": "text"
      },
      "source": [
        "Given below is a function to prepare the sequences. It will also perform sequence padding to a maximum sentence length as mentioned above. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1piTg_rqSwt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# encode and pad sequences\n",
        "def encode_sequences(tokenizer, length, lines):\n",
        "    # integer encode sequences\n",
        "    seq = tokenizer.texts_to_sequences(lines)\n",
        "    # pad sequences with 0 values\n",
        "    seq = pad_sequences(seq, maxlen=length, padding='post')\n",
        "    print(seq)\n",
        "    print(len(seq))\n",
        "    return seq"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MaULsvIpqSwv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U7-rHCJGqSwx",
        "colab_type": "text"
      },
      "source": [
        "### Model Building"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jviun848qSwy",
        "colab_type": "text"
      },
      "source": [
        "We will now split the data into train and test set for model training and evaluation, respectively."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQwd0ywpqSwy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train, test = train_test_split(spa_eng, test_size=0.2, random_state = 12)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8J7A7bqZqSw2",
        "colab_type": "text"
      },
      "source": [
        "It's time to encode the sentences. We will encode Spanish sentences as the input sequences and English sentences as the target sequences. It will be done for both train and test datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kla65K9GqSw2",
        "colab_type": "code",
        "outputId": "092ae05a-c643-47a3-ce21-441c44c947b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# prepare training data\n",
        "trainX = encode_sequences(spa_tokenizer, spa_length, train[:, 1])\n",
        "trainY = encode_sequences(spa_tokenizer, spa_length, train[:, 0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 8  0  0  0  0  0  0  0]\n",
            " [43  0  0  0  0  0  0  0]\n",
            " [42  0  0  0  0  0  0  0]\n",
            " [19  0  0  0  0  0  0  0]\n",
            " [34 35  0  0  0  0  0  0]\n",
            " [ 7  0  0  0  0  0  0  0]\n",
            " [29  0  0  0  0  0  0  0]\n",
            " [15  0  0  0  0  0  0  0]\n",
            " [38 39 40  0  0  0  0  0]\n",
            " [ 3  1  2  0  0  0  0  0]\n",
            " [23  0  0  0  0  0  0  0]\n",
            " [20  8  0  0  0  0  0  0]\n",
            " [27  0  0  0  0  0  0  0]\n",
            " [48  0  0  0  0  0  0  0]\n",
            " [36 37  0  0  0  0  0  0]\n",
            " [ 7  0  0  0  0  0  0  0]\n",
            " [26  0  0  0  0  0  0  0]\n",
            " [ 9  0  0  0  0  0  0  0]\n",
            " [32 33  0  0  0  0  0  0]\n",
            " [ 5  0  0  0  0  0  0  0]\n",
            " [50  0  0  0  0  0  0  0]\n",
            " [44  0  0  0  0  0  0  0]\n",
            " [21  0  0  0  0  0  0  0]\n",
            " [45  0  0  0  0  0  0  0]\n",
            " [49  0  0  0  0  0  0  0]\n",
            " [ 3  0  0  0  0  0  0  0]\n",
            " [16  0  0  0  0  0  0  0]\n",
            " [ 4  1  2  0  0  0  0  0]\n",
            " [ 6  0  0  0  0  0  0  0]\n",
            " [28  0  0  0  0  0  0  0]\n",
            " [18  0  0  0  0  0  0  0]\n",
            " [11  0  0  0  0  0  0  0]\n",
            " [25  0  0  0  0  0  0  0]\n",
            " [ 6  0  0  0  0  0  0  0]\n",
            " [51  0  0  0  0  0  0  0]\n",
            " [10  0  0  0  0  0  0  0]\n",
            " [ 4  0  0  0  0  0  0  0]\n",
            " [12  0  0  0  0  0  0  0]\n",
            " [ 5  0  0  0  0  0  0  0]\n",
            " [17  0  0  0  0  0  0  0]]\n",
            "40\n",
            "[[ 0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0]\n",
            " [37  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0]]\n",
            "40\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g41ioc6LfxH5",
        "colab_type": "code",
        "outputId": "d6d09d3c-6f00-44bf-db4d-0a15409ec28c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "train[:, 0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['help', 'shoot', 'shoot', 'help', 'i won', 'fire', 'go on', 'run',\n",
              "       'relax', 'go now', 'stop', 'help', 'wait', 'attack', 'oh no',\n",
              "       'shoot', 'wait', 'go', 'i try', 'hi', 'attack', 'shoot', 'jump',\n",
              "       'smile', 'attack', 'go', 'who', 'go now', 'shoot', 'go on', 'fire',\n",
              "       'run', 'stop', 'fire', 'attack', 'go', 'go', 'run', 'hello', 'wow'],\n",
              "      dtype='<U332')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSFtnLqCqSw4",
        "colab_type": "code",
        "outputId": "60ab8a99-4f37-4b43-f0c9-7ef06161992e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "print(trainX.shape)\n",
        "print(trainY.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(40, 8)\n",
            "(40, 8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "keNJpyqSqSw8",
        "colab_type": "code",
        "outputId": "98e1bd8d-af1f-4f7b-a64e-256c618fc479",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        }
      },
      "source": [
        "# prepare validation data\n",
        "testX = encode_sequences(spa_tokenizer, spa_length, test[:, 1])\n",
        "testY = encode_sequences(eng_tokenizer, eng_length, test[:, 0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[30  0  0  0  0  0  0  0]\n",
            " [52  0  0  0  0  0  0  0]\n",
            " [13  0  0  0  0  0  0  0]\n",
            " [46 47  0  0  0  0  0  0]\n",
            " [41  0  0  0  0  0  0  0]\n",
            " [31  0  0  0  0  0  0  0]\n",
            " [24  0  0  0  0  0  0  0]\n",
            " [53  1  2  0  0  0  0  0]\n",
            " [22  0  0  0  0  0  0  0]\n",
            " [14  0  0  0  0  0  0  0]]\n",
            "10\n",
            "[[ 5 13  0  0  0  0  0  0]\n",
            " [24 25  0  0  0  0  0  0]\n",
            " [ 3  0  0  0  0  0  0  0]\n",
            " [ 4  0  0  0  0  0  0  0]\n",
            " [ 2  0  0  0  0  0  0  0]\n",
            " [ 5 13  0  0  0  0  0  0]\n",
            " [ 8  0  0  0  0  0  0  0]\n",
            " [ 1  9  0  0  0  0  0  0]\n",
            " [10  0  0  0  0  0  0  0]\n",
            " [ 3  0  0  0  0  0  0  0]]\n",
            "10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nm_FOR2qSw_",
        "colab_type": "code",
        "outputId": "6f9b85ad-479f-4608-ee1c-88f1c7bb889f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "print(testX.shape)\n",
        "print(testY.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10, 8)\n",
            "(10, 8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hoOYBQz0qSxC",
        "colab_type": "text"
      },
      "source": [
        "Now comes the exciting part! Let us define our Seq2Seq model architecture. We are using an Embedding layer and an LSTM layer as our encoder and another LSTM layer followed by a Dense layer as the decoder.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxrAswegqSxC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# build NMT model\n",
        "def build_model(in_vocab, out_vocab, in_timesteps, out_timesteps, units):\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(in_vocab, units, input_length=in_timesteps, mask_zero=True))\n",
        "    model.add(LSTM(units))\n",
        "    model.add(RepeatVector(out_timesteps))    \n",
        "    model.add(LSTM(units, return_sequences=True))\n",
        "    model.add(Dense(out_vocab, activation='softmax'))\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNt5Jg4YqSxF",
        "colab_type": "text"
      },
      "source": [
        "Details about the RepeatVector :  https://campus.datacamp.com/courses/machine-translation-in-python/implementing-an-encoder-decoder-model-with-keras?ex=6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4IhdTnCUqSxF",
        "colab_type": "text"
      },
      "source": [
        "We are using RMSprop optimizer in this model as it is usually a good choice for recurrent neural networks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QC2JUc9UqSxG",
        "colab_type": "code",
        "outputId": "aaed9712-a7df-478d-d0fe-ce30f3c41812",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "print(spa_vocab_size)\n",
        "print(eng_vocab_size)\n",
        "print(spa_length)\n",
        "print(eng_length)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "54\n",
            "26\n",
            "8\n",
            "8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTy5ETwsqSxI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = build_model(spa_vocab_size, eng_vocab_size, spa_length, eng_length, 64)\n",
        "rms = optimizers.RMSprop(lr=0.1)\n",
        "model.compile(optimizer=rms, loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FK5fqdXWqSxK",
        "colab_type": "text"
      },
      "source": [
        "Please note that we have used __'sparse_categorical_crossentropy'__ as the loss function because it allows us to use the target sequence as it is instead of one hot encoded format. One hot encoding the target sequences with such a huge vocabulary might consume our system's entire memory."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0fCQo0gqSxL",
        "colab_type": "text"
      },
      "source": [
        "It seems we are all set to start training our model. We will train it for 30 epochs and with a batch size of 512. You may change and play these hyperparameters. We will also be using __ModelCheckpoint()__ to save the best model with lowest validation loss. I personally prefer this method over early stopping."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXqS_RGozeiH",
        "colab_type": "code",
        "outputId": "e248e9f0-b7b8-4960-ec03-744529d70042",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "de_eng\t     LAB_TEXT_MachineTranslation_DE_EN.ipynb  README.md  spa-eng.zip\n",
            "deu-eng.zip  model.h1.24_jan_19\t\t\t      spa-eng\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "jWGTn32sqSxL",
        "colab_type": "code",
        "outputId": "17bc6800-b9f9-4c01-c0f1-cb57bb7ccf0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "filename = 'model.h1.24_jan_19'\n",
        "checkpoint = ModelCheckpoint(filename, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
        "\n",
        "history = model.fit(trainX, trainY.reshape(trainY.shape[0], trainY.shape[1], 1), \n",
        "          epochs=30, batch_size=64, \n",
        "          validation_split = 0.1,\n",
        "          callbacks=[checkpoint], verbose=1)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 36 samples, validate on 4 samples\n",
            "Epoch 1/30\n",
            "36/36 [==============================] - 1s 18ms/step - loss: nan - accuracy: 0.0660 - val_loss: 3.2581 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00001: loss did not improve from inf\n",
            "Epoch 2/30\n",
            "36/36 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.9965 - val_loss: 3.2581 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00002: loss did not improve from inf\n",
            "Epoch 3/30\n",
            "36/36 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.9965 - val_loss: 3.2581 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00003: loss did not improve from inf\n",
            "Epoch 4/30\n",
            "36/36 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.9965 - val_loss: 3.2581 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00004: loss did not improve from inf\n",
            "Epoch 5/30\n",
            "36/36 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.9965 - val_loss: 3.2581 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00005: loss did not improve from inf\n",
            "Epoch 6/30\n",
            "36/36 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.9965 - val_loss: 3.2581 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00006: loss did not improve from inf\n",
            "Epoch 7/30\n",
            "36/36 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.9965 - val_loss: 3.2581 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00007: loss did not improve from inf\n",
            "Epoch 8/30\n",
            "36/36 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.9965 - val_loss: 3.2581 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00008: loss did not improve from inf\n",
            "Epoch 9/30\n",
            "36/36 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.9965 - val_loss: 3.2581 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00009: loss did not improve from inf\n",
            "Epoch 10/30\n",
            "36/36 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.9965 - val_loss: 3.2581 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00010: loss did not improve from inf\n",
            "Epoch 11/30\n",
            "36/36 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.9965 - val_loss: 3.2581 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00011: loss did not improve from inf\n",
            "Epoch 12/30\n",
            "36/36 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.9965 - val_loss: 3.2581 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00012: loss did not improve from inf\n",
            "Epoch 13/30\n",
            "36/36 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.9965 - val_loss: 3.2581 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00013: loss did not improve from inf\n",
            "Epoch 14/30\n",
            "36/36 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.9965 - val_loss: 3.2581 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00014: loss did not improve from inf\n",
            "Epoch 15/30\n",
            "36/36 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.9965 - val_loss: 3.2581 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00015: loss did not improve from inf\n",
            "Epoch 16/30\n",
            "36/36 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.9965 - val_loss: 3.2581 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00016: loss did not improve from inf\n",
            "Epoch 17/30\n",
            "36/36 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.9965 - val_loss: 3.2581 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00017: loss did not improve from inf\n",
            "Epoch 18/30\n",
            "36/36 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.9965 - val_loss: 3.2581 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00018: loss did not improve from inf\n",
            "Epoch 19/30\n",
            "36/36 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.9965 - val_loss: 3.2581 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00019: loss did not improve from inf\n",
            "Epoch 20/30\n",
            "36/36 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.9965 - val_loss: 3.2581 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00020: loss did not improve from inf\n",
            "Epoch 21/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.9965 - val_loss: 3.2581 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00021: loss did not improve from inf\n",
            "Epoch 22/30\n",
            "36/36 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.9965 - val_loss: 3.2581 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00022: loss did not improve from inf\n",
            "Epoch 23/30\n",
            "36/36 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.9965 - val_loss: 3.2581 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00023: loss did not improve from inf\n",
            "Epoch 24/30\n",
            "36/36 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.9965 - val_loss: 3.2581 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00024: loss did not improve from inf\n",
            "Epoch 25/30\n",
            "36/36 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.9965 - val_loss: 3.2581 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00025: loss did not improve from inf\n",
            "Epoch 26/30\n",
            "36/36 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.9965 - val_loss: 3.2581 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00026: loss did not improve from inf\n",
            "Epoch 27/30\n",
            "36/36 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.9965 - val_loss: 3.2581 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00027: loss did not improve from inf\n",
            "Epoch 28/30\n",
            "36/36 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.9965 - val_loss: 3.2581 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00028: loss did not improve from inf\n",
            "Epoch 29/30\n",
            "36/36 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.9965 - val_loss: 3.2581 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00029: loss did not improve from inf\n",
            "Epoch 30/30\n",
            "36/36 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.9965 - val_loss: 3.2581 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00030: loss did not improve from inf\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1vK99OnMqSxN",
        "colab_type": "text"
      },
      "source": [
        "Let's compare the training loss and the validation loss."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOJyVqi_qSxO",
        "colab_type": "code",
        "outputId": "dd6a45e6-17e6-4177-8d0d-deec7653023d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.legend(['train','validation'])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXsAAAD4CAYAAAANbUbJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAWzElEQVR4nO3dfZBV9Z3n8fcn2LF5Smigo0CzwmRN7NAQGq/ELR+C+ISxQjRRcRKrIDUJE8usprJTNUxmKwqJVW4mQ1GpMj6k1pRbFcMyOCrrhnFwqpmEMjx0J9DylKARQ0OEFoPa4WEVv/vHPTLXTj/cC7e7vff3eVXd6nPO73dOf3+c4tOnf/f0uYoIzMysun1gqAswM7OB57A3M0uAw97MLAEOezOzBDjszcwScNZQF9Dd+PHjY8qUKUNdhplZRWlra3s1Iup7a3/fhf2UKVNobW0d6jLMzCqKpJf7avc0jplZAhz2ZmYJcNibmSXgfTdnb2bV5a233qKjo4Pjx48PdSlVoba2loaGBmpqakraz2FvZgOqo6OD0aNHM2XKFCQNdTkVLSI4fPgwHR0dTJ06taR9PY1jZgPq+PHjjBs3zkFfBpIYN27caf2W5LA3swHnoC+f0/23dNibmSXAYW9mVe3IkSP88Ic/LHm/z3zmMxw5cmQAKhoaDnszq2q9hf3bb7/d534/+9nPGDNmzECVNeh8N46ZVbUlS5bw4osvMnPmTGpqaqitraWuro7du3fz29/+lhtuuIF9+/Zx/Phx7rrrLhYvXgz8x6Nburq6uO6667j00kt57rnnmDRpEk899RTDhw8f4pGVxmFvZoNm6f/Zwc4Db5T1mJ+Y+CHu/uy0Xtvvu+8+tm/fztatW1m/fj3XX38927dvP3Xr4iOPPMLYsWM5duwYF110EV/4whcYN27ce46xZ88efvrTn/KjH/2IW265hccff5zbbrutrOMYaA57M0vK7Nmz33OP+g9+8AOeeOIJAPbt28eePXv+LOynTp3KzJkzAbjwwgvZu3fvoNVbLg57Mxs0fV2BD5aRI0eeWl6/fj3PPvssv/zlLxkxYgRz5szp8R72s88++9TysGHDOHbs2KDUWk5+g9bMqtro0aN58803e2x7/fXXqaurY8SIEezevZuNGzcOcnWDx1f2ZlbVxo0bxyWXXEJTUxPDhw/nnHPOOdU2b948HnzwQRobG/n4xz/OxRdfPISVDixFxFDX8B65XC784SVm1WPXrl00NjYOdRlVpad/U0ltEZHrbR9P45iZJaDfsJdUK2mzpG2Sdkha2kffL0gKSbmCbX8n6QVJv5F0bbkKNzOz4hUzZ38CmBsRXZJqgA2S1kbEe97JkDQauAvYVLDtE8CtwDRgIvCspI9FxMmyjcDMzPrV75V95HVlqzXZq6eJ/u8A/wMovG/pc8DKiDgRES8BLwCzz6xkMzMrVVFz9pKGSdoKHALWRcSmbu2zgMkR8X+77ToJ2Few3pFt6378xZJaJbV2dnaWNAAzM+tfUWEfEScjYibQAMyW1PRum6QPAMuB/3a6RUTEwxGRi4hcfX396R7GzMx6UdLdOBFxBGgB5hVsHg00Aesl7QUuBtZkb9LuByYX9G3ItpmZvS+NGjUKgAMHDnDTTTf12GfOnDn0d4v4ihUrOHr06Kn1oX5kcjF349RLGpMtDweuBna/2x4Rr0fE+IiYEhFTgI3A/IhoBdYAt0o6W9JU4Hxg8wCMw8ysrCZOnMjq1atPe//uYT/Uj0wu5sp+AtAiqR3YQn7O/mlJyyTN72vHiNgBrAJ2Av8C3OE7ccxsMC1ZsoT777//1Po999zDd7/7Xa688kpmzZrF9OnTeeqpp/5sv71799LUlJ+xPnbsGLfeeiuNjY3ceOON73k2zu23304ul2PatGncfffdQP7hagcOHOCKK67giiuuAPKPTH711VcBWL58OU1NTTQ1NbFixYpT36+xsZGvfvWrTJs2jWuuuaasz+Dp99bLiGgHmnvY/u1e+s/ptn4vcO9p1mdm1WTtEnjl+fIe89zpcN19vTYvWLCAb3zjG9xxxx0ArFq1imeeeYY777yTD33oQ7z66qtcfPHFzJ8/v9fPd33ggQcYMWIEu3btor29nVmzZp1qu/feexk7diwnT57kyiuvpL29nTvvvJPly5fT0tLC+PHj33OstrY2fvzjH7Np0yYigk996lN8+tOfpq6ubkAfpey/oDWzqtbc3MyhQ4c4cOAA27Zto66ujnPPPZdvfetbzJgxg6uuuor9+/dz8ODBXo/x85///FTozpgxgxkzZpxqW7VqFbNmzaK5uZkdO3awc+fOPuvZsGEDN954IyNHjmTUqFF8/vOf5xe/+AUwsI9S9oPQzGzw9HEFPpBuvvlmVq9ezSuvvMKCBQv4yU9+QmdnJ21tbdTU1DBlypQeH23cn5deeonvf//7bNmyhbq6OhYtWnRax3nXQD5K2Vf2Zlb1FixYwMqVK1m9ejU333wzr7/+Oh/5yEeoqamhpaWFl19+uc/9L7/8ch577DEAtm/fTnt7OwBvvPEGI0eO5MMf/jAHDx5k7dq1p/bp7dHKl112GU8++SRHjx7lT3/6E0888QSXXXZZGUfbM1/Zm1nVmzZtGm+++SaTJk1iwoQJfOlLX+Kzn/0s06dPJ5fLccEFF/S5/+23386Xv/xlGhsbaWxs5MILLwTgk5/8JM3NzVxwwQVMnjyZSy655NQ+ixcvZt68eUycOJGWlpZT22fNmsWiRYuYPTv/MIGvfOUrNDc3D/inX/kRx2Y2oPyI4/LzI47NzKxHDnszswQ47M1swL3fposr2en+WzrszWxA1dbWcvjwYQd+GUQEhw8fpra2tuR9fTeOmQ2ohoYGOjo68OPLy6O2tpaGhoaS93PYm9mAqqmpYerUqUNdRvI8jWNmlgCHvZlZAhz2ZmYJcNibmSXAYW9mlgCHvZlZAhz2ZmYJcNibmSXAYW9mlgCHvZlZAvoNe0m1kjZL2iZph6SlPfT5mqTnJW2VtEHSJ7LtUyQdy7ZvlfTgQAzCzMz6VsyzcU4AcyOiS1INsEHS2ojYWNDnsYh4EEDSfGA5MC9rezEiZpa1ajMzK0m/YR/555J2Zas12Su69XmjYHVk93YzMxtaRc3ZSxomaStwCFgXEZt66HOHpBeB7wF3FjRNlfRrSf8uqcePUJe0WFKrpFY/BtXMrPxK+sBxSWOAJ4D/GhHbe+nzReDaiFgo6WxgVEQclnQh8CQwrdtvAu/hDxw3MytdWT9wPCKOAC38x3x8T1YCN2T9T0TE4Wy5DXgR+Fgp39PMzM5cMXfj1GdX9EgaDlwN7O7W5/yC1euBPQX7DsuW/wI4H/hdeUo3M7NiFXM3zgTg0Sy0PwCsioinJS0DWiNiDfB1SVcBbwF/BBZm+14OLJP0FvAO8LWIeK3sozAzsz6VNGc/GDxnb2ZWurLO2ZuZWWVy2JuZJcBhb2aWAIe9mVkCHPZmZglw2JuZJcBhb2aWAIe9mVkCHPZmZglw2JuZJcBhb2aWAIe9mVkCHPZmZglw2JuZJcBhb2aWAIe9mVkCHPZmZglw2JuZJcBhb2aWAIe9mVkCHPZmZgnoN+wl1UraLGmbpB2SlvbQ52uSnpe0VdIGSZ8oaPs7SS9I+o2ka8s9ADMz699ZRfQ5AcyNiC5JNcAGSWsjYmNBn8ci4kEASfOB5cC8LPRvBaYBE4FnJX0sIk6WdxhmZtaXfq/sI68rW63JXtGtzxsFqyML2j8HrIyIExHxEvACMPuMqzYzs5IUc2WPpGFAG/CfgfsjYlMPfe4Avgl8EJibbZ4EFP4G0JFtMzOzQVTUG7QRcTIiZgINwGxJTT30uT8iPgr8LfDfSylC0mJJrZJaOzs7S9nVzMyKUNLdOBFxBGgB5vXRbSVwQ7a8H5hc0NaQbet+3IcjIhcRufr6+lJKMjOzIhRzN069pDHZ8nDgamB3tz7nF6xeD+zJltcAt0o6W9JU4HxgczkKNzOz4hUzZz8BeDSbt/8AsCoinpa0DGiNiDXA1yVdBbwF/BFYCBAROyStAnYCbwN3+E4cM7PBp4jov9cgyuVy0draOtRlmJlVFEltEZHrrd1/QWtmlgCHvZlZAhz2ZmYJcNibmSXAYW9mlgCHvZlZAhz2ZmYJcNibmSXAYW9mlgCHvZlZAhz2ZmYJcNibmSXAYW9mlgCHvZlZAhz2ZmYJcNibmSXAYW9mlgCHvZlZAhz2ZmYJKOYDxyvH2iXwyvNDXYWZ2ek5dzpcd9+AHNpX9mZmCaiuK/sB+oloZlbp+r2yl1QrabOkbZJ2SFraQ59vStopqV3Sv0k6r6DtpKSt2WtNuQdgZmb9K+bK/gQwNyK6JNUAGyStjYiNBX1+DeQi4qik24HvAQuytmMRMbO8ZZuZWSn6vbKPvK5stSZ7Rbc+LRFxNFvdCDSUtUozMzsjRb1BK2mYpK3AIWBdRGzqo/tfAWsL1msltUraKOmGXo6/OOvT2tnZWXTxZmZWnKLCPiJOZlMxDcBsSU099ZN0G5AD/qFg83kRkQO+CKyQ9NEejv9wROQiIldfX1/yIMzMrG8l3XoZEUeAFmBe9zZJVwF/D8yPiBMF++zPvv4OWA80n0G9ZmZ2Goq5G6de0phseThwNbC7W59m4CHyQX+oYHudpLOz5fHAJcDO8pVvZmbFKOZunAnAo5KGkf/hsCoinpa0DGiNiDXkp21GAf8kCeD3ETEfaAQekvROtu99EeGwNzMbZP2GfUS008PUS0R8u2D5ql72fQ6YfiYFmpnZmfPjEszMEuCwNzNLgMPezCwBDnszswQ47M3MEuCwNzNLgMPezCwBDnszswQ47M3MEuCwNzNLgMPezCwBDnszswQ47M3MEuCwNzNLgMPezCwBDnszswQ47M3MEuCwNzNLgMPezCwBDnszswQ47M3MEtBv2EuqlbRZ0jZJOyQt7aHPNyXtlNQu6d8knVfQtlDSnuy1sNwDMDOz/hVzZX8CmBsRnwRmAvMkXdytz6+BXETMAFYD3wOQNBa4G/gUMBu4W1JduYo3M7Pi9Bv2kdeVrdZkr+jWpyUijmarG4GGbPlaYF1EvBYRfwTWAfPKUrmZmRWtqDl7ScMkbQUOkQ/vTX10/ytgbbY8CdhX0NaRbet+/MWSWiW1dnZ2Fle5mZkVraiwj4iTETGT/BX7bElNPfWTdBuQA/6hlCIi4uGIyEVErr6+vpRdzcysCCXdjRMRR4AWepiKkXQV8PfA/Ig4kW3eD0wu6NaQbTMzs0FUzN049ZLGZMvDgauB3d36NAMPkQ/6QwVNzwDXSKrL3pi9JttmZmaD6Kwi+kwAHpU0jPwPh1UR8bSkZUBrRKwhP20zCvgnSQC/j4j5EfGapO8AW7JjLYuI18o/DDMz64siov9egyiXy0Vra+tQl2FmVlEktUVErrd2/wWtmVkCHPZmZglw2JuZJcBhb2aWAIe9mVkCHPZmZglw2JuZJcBhb2aWAIe9mVkCHPZmZglw2JuZJcBhb2aWAIe9mVkCHPZmZglw2JuZJcBhb2aWAIe9mVkCHPZmZglw2JuZJcBhb2aWAIe9mVkCHPZmZgnoN+wl1UraLGmbpB2SlvbQ53JJv5L0tqSburWdlLQ1e60pZ/FmZlacs4rocwKYGxFdkmqADZLWRsTGgj6/BxYBf9PD/sciYuaZl2pmZqer37CPiAC6stWa7BXd+uwFkPROmeszM7MyKGrOXtIwSVuBQ8C6iNhUwveoldQqaaOkG3o5/uKsT2tnZ2cJhzYzs2IUFfYRcTKbimkAZktqKuF7nBcROeCLwApJH+3h+A9HRC4icvX19SUc2szMilHS3TgRcQRoAeaVsM/+7OvvgPVAcynf08zMzlwxd+PUSxqTLQ8HrgZ2F3NwSXWSzs6WxwOXADtPv1wzMzsdxVzZTwBaJLUDW8jP2T8taZmk+QCSLpLUAdwMPCRpR7ZvI9AqaRv53wjuiwiHvZnZICvmbpx2eph6iYhvFyxvIT+f373Pc8D0M6zRzMzOkP+C1swsAQ57M7MEOOzNzBLgsDczS4DD3swsAQ57M7MEOOzNzBLgsDczS4DD3swsAQ57M7MEOOzNzBLgsDczS4DD3swsAQ57M7MEOOzNzBLgsDczS4DD3swsAQ57M7MEOOzNzBLgsDczS4DD3swsAf2GvaRaSZslbZO0Q9LSHvpcLulXkt6WdFO3toWS9mSvheUs3szMinNWEX1OAHMjoktSDbBB0tqI2FjQ5/fAIuBvCneUNBa4G8gBAbRJWhMRfyxL9WZmVpR+r+wjrytbrcle0a3P3ohoB97ptvu1wLqIeC0L+HXAvDMv28zMSlHUnL2kYZK2AofIh/emIo8/CdhXsN6Rbet+/MWSWiW1dnZ2FnloMzMrVlFhHxEnI2Im0ADMltRUziIi4uGIyEVErr6+vpyHNjMzSrwbJyKOAC0UPxWzH5hcsN6QbTMzs0FUzN049ZLGZMvDgauB3UUe/xngGkl1kuqAa7JtZmY2iIq5sp8AtEhqB7aQn7N/WtIySfMBJF0kqQO4GXhI0g6AiHgN+E623xZgWbbNzMwGkSKi/16DKJfLRWtr61CXYWZWUSS1RUSut3b/Ba2ZWQIc9mZmCXDYm5klwGFvZpYAh72ZWQIc9mZmCXDYm5kl4H13n72kTuDlMzjEeODVMpXzflBt44HqG1O1jQeqb0zVNh748zGdFxG9PlzsfRf2Z0pSa19/WFBpqm08UH1jqrbxQPWNqdrGA6WPydM4ZmYJcNibmSWgGsP+4aEuoMyqbTxQfWOqtvFA9Y2p2sYDJY6p6ubszczsz1Xjlb2ZmXXjsDczS0DVhL2keZJ+I+kFSUuGup5ykLRX0vOStkqquIf8S3pE0iFJ2wu2jZW0TtKe7GvdUNZYql7GdI+k/dl52irpM0NZYykkTZbUImmnpB2S7sq2V+R56mM8lXyOaiVtlrQtG9PSbPtUSZuyzPvfkj7Y53GqYc5e0jDgt+Q/MrGD/Kdi/WVE7BzSws6QpL1ALiIq8o9BJF0OdAH/KyKasm3fA16LiPuyH8p1EfG3Q1lnKXoZ0z1AV0R8fyhrOx2SJgATIuJXkkYDbcANwCIq8Dz1MZ5bqNxzJGBkRHRJqgE2AHcB3wT+OSJWSnoQ2BYRD/R2nGq5sp8NvBARv4uI/wesBD43xDUlLyJ+DnT/GMrPAY9my4+S/49YMXoZU8WKiD9ExK+y5TeBXcAkKvQ89TGeihV5XdlqTfYKYC6wOtve7zmqlrCfBOwrWO+gwk9wJoB/ldQmafFQF1Mm50TEH7LlV4BzhrKYMvq6pPZsmqcipjy6kzQFaAY2UQXnqdt4oILPkaRhkrYCh4B1wIvAkYh4O+vSb+ZVS9hXq0sjYhZwHXBHNoVQNSI/h1j584jwAPBRYCbwB+Afh7ac0kkaBTwOfCMi3ihsq8Tz1MN4KvocRcTJiJgJNJCfybig1GNUS9jvByYXrDdk2ypaROzPvh4CniB/kivdwWxe9d351UNDXM8Zi4iD2X/Gd4AfUWHnKZsHfhz4SUT8c7a5Ys9TT+Op9HP0rog4ArQA/wUYI+msrKnfzKuWsN8CnJ+9O/1B4FZgzRDXdEYkjczeYELSSOAaYHvfe1WENcDCbHkh8NQQ1lIW74Zi5kYq6Dxlb/79T2BXRCwvaKrI89TbeCr8HNVLGpMtDyd/I8ou8qF/U9at33NUFXfjAGS3Uq0AhgGPRMS9Q1zSGZH0F+Sv5gHOAh6rtDFJ+ikwh/yjWA8CdwNPAquA/0T+Uda3RETFvOHZy5jmkJ8eCGAv8NcF893va5IuBX4BPA+8k23+Fvl57oo7T32M5y+p3HM0g/wbsMPIX6CviohlWUasBMYCvwZui4gTvR6nWsLezMx6Vy3TOGZm1geHvZlZAhz2ZmYJcNibmSXAYW9mlgCHvZlZAhz2ZmYJ+P9qu3J1H+gxQgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70U3WRK4qSxQ",
        "colab_type": "text"
      },
      "source": [
        "### Make Predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hI97t9FqSxR",
        "colab_type": "text"
      },
      "source": [
        "Let's load the saved model to make predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JqyEnceNqSxS",
        "colab_type": "code",
        "outputId": "ad78011c-5003-41a4-b794-e406c4bdd6c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "model = load_model('model.h1.24_jan_19')\n",
        "preds = model.predict_classes(testX.reshape((testX.shape[0],testX.shape[1])))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFx8LT5oqSxU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_word(n, tokenizer):\n",
        "    for word, index in tokenizer.word_index.items():\n",
        "        if index == n:\n",
        "            return word\n",
        "    return None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Q-rdOInqSxe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# convert predictions into text (English)\n",
        "preds_text = []\n",
        "for i in preds:\n",
        "    temp = []\n",
        "    for j in range(len(i)):\n",
        "        t = get_word(i[j], eng_tokenizer)\n",
        "        if j > 0:\n",
        "            if (t == get_word(i[j-1], eng_tokenizer)) or (t == None):\n",
        "                temp.append('')\n",
        "            else:\n",
        "                temp.append(t)\n",
        "             \n",
        "        else:\n",
        "            if(t == None):\n",
        "                temp.append('')\n",
        "            else:\n",
        "                temp.append(t)            \n",
        "        \n",
        "    preds_text.append(' '.join(temp))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "318fP5gOqSxh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_df = pd.DataFrame({'actual' : test[:,0], 'predicted' : preds_text})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OAO6jGlgqSxl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.set_option('display.max_colwidth', 200)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VB61oVXdqSxo",
        "colab_type": "code",
        "outputId": "e7b30547-9a23-4be4-fcbb-28051f1e91b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        }
      },
      "source": [
        "pred_df.head(15)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>actual</th>\n",
              "      <th>predicted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>i ran</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>get up</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>run</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>attack</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>shoot</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>i ran</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>stop</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>go now</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>jump</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>run</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   actual predicted\n",
              "0   i ran          \n",
              "1  get up          \n",
              "2     run          \n",
              "3  attack          \n",
              "4   shoot          \n",
              "5   i ran          \n",
              "6    stop          \n",
              "7  go now          \n",
              "8    jump          \n",
              "9     run          "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ilRn-KKaqSxr",
        "colab_type": "code",
        "outputId": "f925023b-b5a5-4177-c5b2-851e010a049f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        }
      },
      "source": [
        "pred_df.tail(15)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>actual</th>\n",
              "      <th>predicted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>i ran</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>get up</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>run</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>attack</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>shoot</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>i ran</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>stop</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>go now</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>jump</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>run</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   actual predicted\n",
              "0   i ran          \n",
              "1  get up          \n",
              "2     run          \n",
              "3  attack          \n",
              "4   shoot          \n",
              "5   i ran          \n",
              "6    stop          \n",
              "7  go now          \n",
              "8    jump          \n",
              "9     run          "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPRhmuwDqSxt",
        "colab_type": "code",
        "outputId": "2151b7bc-a5d8-4d2e-ad72-d27a5d3eade2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        }
      },
      "source": [
        "pred_df.tail(15)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>actual</th>\n",
              "      <th>predicted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>i ran</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>get up</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>run</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>attack</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>shoot</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>i ran</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>stop</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>go now</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>jump</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>run</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   actual predicted\n",
              "0   i ran          \n",
              "1  get up          \n",
              "2     run          \n",
              "3  attack          \n",
              "4   shoot          \n",
              "5   i ran          \n",
              "6    stop          \n",
              "7  go now          \n",
              "8    jump          \n",
              "9     run          "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUiq-dHGqSxw",
        "colab_type": "code",
        "outputId": "26dad35d-c509-41c7-858b-6b6ec036e80e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        }
      },
      "source": [
        "pred_df.sample(15)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-0cc3d4feb4f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpred_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, n, frac, replace, weights, random_state, axis)\u001b[0m\n\u001b[1;32m   5059\u001b[0m             )\n\u001b[1;32m   5060\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5061\u001b[0;31m         \u001b[0mlocs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5062\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5063\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Cannot take a larger sample than population when 'replace=False'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1GnFqivqSx0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}